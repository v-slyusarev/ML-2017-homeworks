{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчёт о решении контеста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формулировка задачи\n",
    "\n",
    "Данные представлены в признаковом описании, где признаками служат:\n",
    "* Num - номер в таблице (целое число; в регрессии не используется)\n",
    "* y - показатель спроса (целое число) - используется в качестве таргета\n",
    "* year - год (целое число от 2012 до 2015)\n",
    "* week - номер недели в году (целое число от 1 до 53)\n",
    "* shift - смена (целое число от 1 до 3, каждую неделю новая смена)\n",
    "* item_id - номер товара (целое число; в регрессии не используется, поскольку не имеет количественного смысла)\n",
    "* f1, f2, ..., f60 -  предподсчитанные средние значения продаж по разным срезам (целые числа)\n",
    "Необходимо по данной таблице признаков предсказать столбец y - величину спроса.\n",
    "Показателем качества предсказания служит $SMAPE = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\frac{2|\\hat{y}_i - y_i|}{|\\hat{y}_i| + |y_i|}$\n",
    "\n",
    "### Описание решения\n",
    "Поскольку в таблице признаков представлены только числовые значения (номер и идентификатор товара, как не имеющие количественного смысла, мы исключаем из таблицы), можно провести регрессию по всем признакам. Столбец 'y' будет служить таргетом для регрессии.\n",
    "В качестве основного алгоритма используются ансамбли решающих деревьев, поскольку данные не позволяют построить адекватную интерпретируемую линейную модель. \n",
    "\n",
    "### Подходы к решению\n",
    "Очевидно, \"сырое\" решающее дерево не даёт удовлетворительного результата. Для решения использовались различные ансамбли решающих деревьев: GradientBoostingRegressor и RandomForestRegressor из библиотеки sklearn и XGBRegressor из библиотеки XGBoost. Среди перечисленных последний лидирует по качеству на тестовой выборке с большим отрывом: MAE порядка $3 \\times 10^5$ против $5 \\times 10^5$ и более. Из параметров регрессии сначала настраивалось n_estimators - число деревьев в ансамбле (из соображений возможности вычислить за разумное время и простых оценок качества, полученных из графиков $MAE = f(n\\_estimators)$. Затем перебором по нескольким небольшим значениям и сравнением MAE были настроены параметры max_depth - максимальная глубина дерева и min_child_weight - ограничение по количеству элементов обучающей выборки в узле дерева. Эти параметры помогают избежать переобучения. MAE оценивалось по 3-fold кроссвалидации. Следует отметить, что рост MAE не всегда приводит к росту SMAPE, но в целом для грубой оценки можно довольствоваться MAE, поскольку обе метрики определяются модулями разности предсказания и истинного значения.\n",
    "\n",
    "### Код\n",
    "Ниже приведён код решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\")\n",
    "test = pd.read_csv(\"test.tsv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.tsv\")\n",
    "\n",
    "X = train.drop(['Num','y'], axis=1)\n",
    "y = train['y']\n",
    "\n",
    "#from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "n = 80\n",
    "max_depth = 12\n",
    "min_child_weight = 2\n",
    "\n",
    "model = XGBRegressor(n_estimators=n, max_depth=max_depth,\n",
    "                     min_child_weight=min_child_weight)\n",
    "    \n",
    "model.fit(X, y)\n",
    "\n",
    "preds = model.predict(test.drop(['Num'], axis=1))\n",
    "\n",
    "score_mae = cross_val_score(model, X, y, scoring =  'neg_mean_absolute_error', cv = 3).mean()\n",
    "print(score_mae)\n",
    "\n",
    "sample_submission['y'] = preds\n",
    "sample_submission['y'] = sample_submission['y'].map(lambda x: x if x > 0 else 0.0)\n",
    "sample_submission.to_csv(\"baseline_submission.tsv\", sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Дополнительные вопросы\n",
    "\n",
    "1. sample_submission.tsv является примером предсказания на тестовой выборке. В нём на каждый набор признаков отвечают одним и тем же значением - средним в столбце y обучающей выборки (файла train.csv). Например, в точности такое же число, 198575.912031, является результатом вызова кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198575.912031\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.tsv\")\n",
    "print(train['y'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
